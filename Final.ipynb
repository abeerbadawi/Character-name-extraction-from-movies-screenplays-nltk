{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# <span style='color:Red'> This code develops an algorithm to read the screenplays and automatically extract the character names from the screenplay and evaluate the model. I developed two different methods to extract character names and compared them with the true label of character names in each movie.  </span>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Import Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 340,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package words to\n",
      "[nltk_data]     C:\\Users\\14379\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package words is already up-to-date!\n",
      "[nltk_data] Downloading package maxent_ne_chunker to\n",
      "[nltk_data]     C:\\Users\\14379\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package maxent_ne_chunker is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "from sklearn.metrics import confusion_matrix\n",
    "import nltk\n",
    "from matplotlib import pyplot as plt\n",
    "import statistics\n",
    "import re\n",
    "from collections import defaultdict\n",
    "from nltk.corpus import stopwords\n",
    "from pattern.en import parse, Sentence, mood\n",
    "from pattern.db import csv\n",
    "from pattern.vector import Document, NB\n",
    "nltk.download('words')\n",
    "nltk.download('maxent_ne_chunker')\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "from wordcloud import WordCloud\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import warnings\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.feature_extraction.text import TfidfTransformer, CountVectorizer, TfidfVectorizer\n",
    "from sklearn.preprocessing import FunctionTransformer\n",
    "from sklearn.calibration import CalibratedClassifierCV\n",
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "from sklearn.pipeline import FeatureUnion, Pipeline\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.base import BaseEstimator, TransformerMixin\n",
    "from sklearn import svm\n",
    "from sklearn.multiclass import OneVsRestClassifier\n",
    "import IPython\n",
    "from IPython.display import display\n",
    "import graphviz\n",
    "from sklearn.tree import export_graphviz"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Cleaning:\n",
    "### 1. Open the movie script file. (Change the file name 'Movie Scripts/Alien-Nation.txt' to any other script in this directory to test different results)\n",
    "### 2. Since character names in the files format is capital letters and each one is in new line I will extract all words that is capital letters and line characters is less than 10\n",
    "### 3. Save the extracted words it in a new file (names.txt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 412,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(r'Movie Scripts/Alien-Nation.txt') as f, open(r'resources/names.txt', 'w') as f2:\n",
    "    for line in f:\n",
    "        line = line.strip()\n",
    "        if not line or (':' not in line and ',' not in line and ' ' not in line and len(line) < 10 and line.isupper()):\n",
    "            f2.write(line + '\\n')\n",
    "            \n",
    "def readText():\n",
    "    \"\"\"\n",
    "    Reads the text from a text file.\n",
    "    \"\"\"\n",
    "    with open(\"resources/names.txt\", \"rb\") as f:\n",
    "        text = f.read().decode('utf-8')\n",
    "    return text"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Extract Characters names using the first method:\n",
    "### 1. Parses text into parts of speech tagged with parts of speech labels using nltk.\n",
    "### 2. Creates a local list to hold nodes of tree passed through, extracting named entities from the chunked sentences.\n",
    "### 3. Uses the global entity list, creating a new dictionary with the properties extended by the local list, without overwriting.\n",
    "### 4. Brings in stopwords and custom stopwords to filter mismatches out.\n",
    "### 5. Convert the output list to a data frame."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 413,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b064a638cc094fbc91241b0ce244205f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Button(description='Toggle Pandas/Lux', layout=Layout(top='5px', width='140px'), style=ButtonStyle())"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3b05ff0b87b841f1920031c52d6ac2d2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Output()"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": []
     },
     "execution_count": 413,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\" Used for reference: https://github.com/emdaniels/character-extraction \"\"\"\n",
    "\n",
    "def chunkSentences(text):\n",
    "    \"\"\"\n",
    "    Parses text into parts of speech tagged with parts of speech labels.\n",
    "\n",
    "    Used for reference: https://gist.github.com/onyxfish/322906\n",
    "    \"\"\"\n",
    "    sentences = nltk.sent_tokenize(text)\n",
    "    tokenizedSentences = [nltk.word_tokenize(sentence)\n",
    "                          for sentence in sentences]\n",
    "    taggedSentences = [nltk.pos_tag(sentence)\n",
    "                       for sentence in tokenizedSentences]\n",
    "    if nltk.__version__[0:2] == \"2.\":\n",
    "        chunkedSentences = nltk.batch_ne_chunk(taggedSentences, binary=True)\n",
    "    else:\n",
    "        chunkedSentences = nltk.ne_chunk_sents(taggedSentences, binary=True)\n",
    "    return chunkedSentences\n",
    "\n",
    "def extractEntityNames(tree, _entityNames=None):\n",
    "    \n",
    "    if _entityNames is None:\n",
    "        _entityNames = []\n",
    "    try:\n",
    "        if nltk.__version__[0:2] == \"2.\":\n",
    "            label = tree.node\n",
    "        else:\n",
    "            label = tree.label()\n",
    "    except AttributeError:\n",
    "        pass\n",
    "    else:\n",
    "        if label == 'NE':\n",
    "            _entityNames.append(' '.join([child[0] for child in tree]))\n",
    "        else:\n",
    "            for child in tree:\n",
    "                extractEntityNames(child, _entityNames=_entityNames)\n",
    "    return _entityNames\n",
    "\n",
    "\n",
    "def buildDict(chunkedSentences, _entityNames=None):\n",
    "\n",
    "    if _entityNames is None:\n",
    "        _entityNames = []\n",
    "\n",
    "    for tree in chunkedSentences:\n",
    "        extractEntityNames(tree, _entityNames=_entityNames)\n",
    "\n",
    "    return _entityNames\n",
    "\n",
    "def removeStopword(entityNames, customStopWords=None):\n",
    "\n",
    "    # Memoize custom stop words\n",
    "    if customStopWords is None:\n",
    "        with open(\"resources/customStopWords.txt\", \"r\") as f:\n",
    "            customStopwords = f.read().split(', ')\n",
    "\n",
    "    for name in entityNames:\n",
    "        if name in stopwords.words('english') or name in customStopwords:\n",
    "            entityNames.remove(name)\n",
    "            \n",
    "text = readText()\n",
    "chunkedSentences = chunkSentences(text)\n",
    "entityNames = buildDict(chunkedSentences)\n",
    "removeStopword(entityNames)\n",
    "\n",
    "def getMajorCharacters(entityNames):\n",
    "    \"\"\"\n",
    "    Adds names to the major character list if they appear frequently.\n",
    "    \"\"\"\n",
    "    x = {name for name in entityNames if ' ' not in name}\n",
    "    data1 = pd.DataFrame(x, columns=['Method 1'])\n",
    "    data1 = data1.sort_values('Method 1')\n",
    "    data1 = data1.reset_index(drop=True)\n",
    "    return data1\n",
    "for i in range(25):\n",
    "    exec(f'df_1 = getMajorCharacters(entityNames)')\n",
    "df_1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Extract Characters names using the second method:\n",
    "### 1. Split all the words extracted from the original file that is capital letters, number of characters in the line less than 10, and the name is repeated minimum five times in the script.\n",
    "### 2. Bring in stopwords and custom stopwords to filter mismatches out.\n",
    "### 3. Convert the output list to a data frame."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 416,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b859d87e23ba47c88493a897d3682ea5",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Button(description='Toggle Pandas/Lux', layout=Layout(top='5px', width='140px'), style=ButtonStyle())"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b03620dc99c141148f4fc7a79f2b6009",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Output()"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": []
     },
     "execution_count": 416,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    " def readText():\n",
    "    \"\"\"\n",
    "    Reads the text from a text file.\n",
    "    \"\"\"\n",
    "    with open(r\"names.txt\", \"r\") as f:\n",
    "        data1 = f.read()\n",
    "        data1 = data1.split()\n",
    "    return data1\n",
    "\n",
    "def removeStopwords(customStopWords=None):\n",
    "    \"\"\"\n",
    "    Brings in stopwords and custom stopwords to filter mismatches out.\n",
    "    \"\"\"\n",
    "    with open(r\"resources/names.txt\", \"r\") as f:\n",
    "        data1 = f.read()\n",
    "        data1 = data1.split()\n",
    "    # Memoize custom stop words\n",
    "    if customStopWords is None:\n",
    "        with open(\"resources/customStopWords.txt\", \"r\") as f:\n",
    "            customStopwords = f.read().split(', ')\n",
    "    for name in data1:\n",
    "        if name in stopwords.words('english') or name in customStopwords or '.' in name or ')' in name:\n",
    "                data1.remove(name)\n",
    "    data = {name for name in data1 if data1.count(name) > 5}\n",
    "    data = pd.DataFrame(data, columns=['Method 2'])\n",
    "    data = data.drop_duplicates(subset=['Method 2'])\n",
    "    data = data.sort_values('Method 2')\n",
    "    data = data.reset_index(drop=True)\n",
    "    return data\n",
    "for i in range(25):\n",
    "    exec(f'df_2 = removeStopwords()')\n",
    "df_2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Extract Characters names using from available dataset with the true label of character names:\n",
    "### 1. Extract the character names for each movie\n",
    "### 2. compare the results with Mehtod one and Method two\n",
    "### 3. Join three datasets in one dataset Called dataset\n",
    "### 4. Save the final dataset in a file name 'Movie Name'_results.csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 408,
   "metadata": {},
   "outputs": [],
   "source": [
    "characters_df = pd.read_csv('True label character names/movie_characters_metadata.tsv', sep='\\t', warn_bad_lines=False,error_bad_lines=False, header=None)\n",
    "characters_df.columns=['chId','True_label','mId','mName','gender','posCredits']\n",
    "characters_df = characters_df.drop(['gender'], axis=1)\n",
    "characters_df = characters_df.drop(['posCredits'], axis=1)\n",
    "characters_df = characters_df.drop(['chId'], axis=1)\n",
    "characters_df = characters_df.drop(['mId'], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 409,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5de6e7edd22c4774acc1b407ec51a319",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Button(description='Toggle Pandas/Lux', layout=Layout(top='5px', width='140px'), style=ButtonStyle())"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "221a7b3b346d4615bef4f33e8f5daa97",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Output()"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": []
     },
     "execution_count": 409,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df1 =  characters_df[147:162]\n",
    "df1 = df1.reset_index(drop=True)\n",
    "df1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 267,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Method 1</th>\n",
       "      <th>Method 2</th>\n",
       "      <th>True_label</th>\n",
       "      <th>mName</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>ANGLE</td>\n",
       "      <td>ANGLE</td>\n",
       "      <td>ANGLE</td>\n",
       "      <td>alien nation</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>CRAIS</td>\n",
       "      <td>CASSANDRA</td>\n",
       "      <td>CASSANDRA</td>\n",
       "      <td>alien nation</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>GOLDRUP</td>\n",
       "      <td>FEDORCHUK</td>\n",
       "      <td>FEDORCHUK</td>\n",
       "      <td>alien nation</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>HARCOURT</td>\n",
       "      <td>HARCOURT</td>\n",
       "      <td>HARCOURT</td>\n",
       "      <td>alien nation</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>JETSON</td>\n",
       "      <td>JETSON</td>\n",
       "      <td>JETSON</td>\n",
       "      <td>alien nation</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>KIPLING</td>\n",
       "      <td>KIPLING</td>\n",
       "      <td>KIPLING</td>\n",
       "      <td>alien nation</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>KRISTIN</td>\n",
       "      <td>O'NEAL</td>\n",
       "      <td>MAFFET</td>\n",
       "      <td>alien nation</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>SYKES</td>\n",
       "      <td>OPERATOR</td>\n",
       "      <td>O'NEAL</td>\n",
       "      <td>alien nation</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>WATSON</td>\n",
       "      <td>PORTER</td>\n",
       "      <td>OPERATOR</td>\n",
       "      <td>alien nation</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>WILTEY</td>\n",
       "      <td>QUINT</td>\n",
       "      <td>PORTER</td>\n",
       "      <td>alien nation</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>NaN</td>\n",
       "      <td>SYKES</td>\n",
       "      <td>SYKES</td>\n",
       "      <td>alien nation</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>NaN</td>\n",
       "      <td>TUGGLE</td>\n",
       "      <td>TUGGLE</td>\n",
       "      <td>alien nation</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>NaN</td>\n",
       "      <td>WARNER</td>\n",
       "      <td>WARNER</td>\n",
       "      <td>alien nation</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>NaN</td>\n",
       "      <td>WATSON</td>\n",
       "      <td>WINTER</td>\n",
       "      <td>alien nation</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>NaN</td>\n",
       "      <td>WILTEY</td>\n",
       "      <td>WILTEY</td>\n",
       "      <td>alien nation</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>NaN</td>\n",
       "      <td>WINTER</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    Method 1   Method 2 True_label         mName\n",
       "0      ANGLE      ANGLE      ANGLE  alien nation\n",
       "1      CRAIS  CASSANDRA  CASSANDRA  alien nation\n",
       "2    GOLDRUP  FEDORCHUK  FEDORCHUK  alien nation\n",
       "3   HARCOURT   HARCOURT   HARCOURT  alien nation\n",
       "4     JETSON     JETSON     JETSON  alien nation\n",
       "5    KIPLING    KIPLING    KIPLING  alien nation\n",
       "6    KRISTIN     O'NEAL     MAFFET  alien nation\n",
       "7      SYKES   OPERATOR     O'NEAL  alien nation\n",
       "8     WATSON     PORTER   OPERATOR  alien nation\n",
       "9     WILTEY      QUINT     PORTER  alien nation\n",
       "10       NaN      SYKES      SYKES  alien nation\n",
       "11       NaN     TUGGLE     TUGGLE  alien nation\n",
       "12       NaN     WARNER     WARNER  alien nation\n",
       "13       NaN     WATSON     WINTER  alien nation\n",
       "14       NaN     WILTEY     WILTEY  alien nation\n",
       "15       NaN     WINTER        NaN           NaN"
      ]
     },
     "execution_count": 267,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset1 = pd.concat([df_1,df_2,df1], axis=1)\n",
    "#dataset1.to_csv(dataset1.mName[0] + '_results.csv', index=True, na_rep=\"None\")\n",
    "dataset1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Evaluate the model performance:\n",
    "### 1. Calculate the true positive and true negative for each method compared with the true label\n",
    "### 2. Calculate the Accuracy, Precision, and recall.\n",
    "### 3. Calculate the mean and Std dev for 10 different movies to find the average result of each method.\n",
    "### 4. Save final results ( TP, FP,  and Accuracy) in a file name Performance_Evaluation-Method1.csv for first method and Performance_Evaluation-Method2.csv for the second method."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 310,
   "metadata": {},
   "outputs": [],
   "source": [
    "def metrics(truth,run):\n",
    "    truth = truth\n",
    "    run = run\n",
    "    TP = float(len(set(run) & set(truth)))\n",
    "    if float(len(run)) >= float(TP):\n",
    "        FP = len(run) - TP\n",
    "    else:\n",
    "        FP = TP - len(run)\n",
    "    TN = 0\n",
    "    if len(truth) >= len(run):\n",
    "        FN = len(truth) - len(run)\n",
    "    else:\n",
    "        FN = 0\n",
    "    accuracy = (float(TP)+float(TN))/float(len(truth))\n",
    "    recall = (float(TP))/float(len(truth))\n",
    "    precision = float(TP)/(float(FP)+float(TP))\n",
    "    print(\"The accuracy is %r\" % accuracy)\n",
    "    print(\"The recall is %r\" % recall)\n",
    "    print(\"The precision is %r\" % precision)\n",
    "    d = {'Predicted Negative': [TN,FN], 'Predicted Positive': [FP,TP]}\n",
    "    metricsdf = pd.DataFrame(d, index=['Negative Cases','Positive Cases'])\n",
    "    df_a = pd.DataFrame(d, columns=['Predicted Positive'])\n",
    "    df_a = df_a.rename(columns={\"Predicted Positive\": \"Predicted Positive 10\"})\n",
    "    df_a['Accuracy10'] = accuracy\n",
    "    df_a.to_csv('Performance_Evaluation.csv', index=True, na_rep=\"None\")\n",
    "    return metricsdf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 311,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The accuracy is 0.4375\n",
      "The recall is 0.4375\n",
      "The precision is 0.4375\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Predicted Negative</th>\n",
       "      <th>Predicted Positive</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Negative Cases</th>\n",
       "      <td>0</td>\n",
       "      <td>9.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Positive Cases</th>\n",
       "      <td>0</td>\n",
       "      <td>7.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                Predicted Negative  Predicted Positive\n",
       "Negative Cases                   0                 9.0\n",
       "Positive Cases                   0                 7.0"
      ]
     },
     "execution_count": 311,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "metrics(dataset1['Method 1'],dataset1['True_label'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 264,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The accuracy is 0.875\n",
      "The recall is 0.875\n",
      "The precision is 0.875\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Predicted Negative</th>\n",
       "      <th>Predicted Positive</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Negative Cases</th>\n",
       "      <td>0</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Positive Cases</th>\n",
       "      <td>0</td>\n",
       "      <td>14.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                Predicted Negative  Predicted Positive\n",
       "Negative Cases                   0                 2.0\n",
       "Positive Cases                   0                14.0"
      ]
     },
     "execution_count": 264,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "metrics(dataset1['Method 2'],dataset1['True_label'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 330,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9c5c4e81a2744752bb47bb09b146f305",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Button(description='Toggle Pandas/Lux', layout=Layout(top='5px', width='140px'), style=ButtonStyle())"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "bb24bf14e638498cb59d463c29800d57",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Output()"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": []
     },
     "execution_count": 330,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Evaluation_method1 = pd.read_csv('Performance Evaluation/Performance_Evaluation-Method1.csv')\n",
    "Evaluation_method1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 331,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.4749\n",
      "0.14221224357354828\n"
     ]
    }
   ],
   "source": [
    "print(Evaluation_method1['Accuracy1'].mean())\n",
    "print(Evaluation_method1['Accuracy1'].std())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 332,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "bb9b64508e644387b12f611dcedb96db",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Button(description='Toggle Pandas/Lux', layout=Layout(top='5px', width='140px'), style=ButtonStyle())"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d559d589324940ab991f35bb0cf7dab6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Output()"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": []
     },
     "execution_count": 332,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Evaluation_method2 = pd.read_csv('Performance Evaluation/Performance_Evaluation-Method2.csv')\n",
    "Evaluation_method2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 333,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.8393999999999998\n",
      "0.06254989119805798\n"
     ]
    }
   ],
   "source": [
    "print(Evaluation_method2['Accuracy2'].mean())\n",
    "print(Evaluation_method2['Accuracy2'].std())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 407,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<Figure size 1440x576 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.figure(figsize=(20,8))\n",
    "mean1 = Evaluation_method1['Accuracy1'].mean() \n",
    "mean2 = Evaluation_method2['Accuracy2'].mean()\n",
    "std1 = Evaluation_method1['Accuracy1'].std()\n",
    "std2 = Evaluation_method2['Accuracy2'].std()\n",
    "Mean = [mean1, mean2]\n",
    "Std =  [std1,std2]\n",
    "values = ['Method 1', 'Method 2']\n",
    "dfx = pd.DataFrame({'Accuracy Mean': Mean,\n",
    "                   'Accuracy Std': Std}, index=values)\n",
    "ax = dfx.plot.bar(rot=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
